{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, I felt quite pleased that I could move away from working with emoji-text. The markov chain was very interesting to me; as I read over the tutorial, I couldn't help but be enamored by the fact that we could now create 'predictive text'. \n",
    "\n",
    "A while back, there was this social media trend where people would post their iMessage predictive text sentences on forums for people to laugh at. The premise was that you could only click on the first word that pops up in the autofill toolbar on iMessage, and continue creating a sentence from the words that the application feeds you. The results varied from \"I like food\" to \"I drink cactus juice\". \n",
    "\n",
    "I really enjoyed this interaction between the user and the software, and I thought it would be interesting to explore the relationship between generative text and direct user-inputted text. In other words, I wanted a human and the machine to co-author a piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "textA = open(\"dracula.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "textB = open(\"uglyduckling.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I imported Markovify, and found two pieces of text to use as test subjects in order to familiarize myself with markov chains. I chose Dracula (a longer length novel) and Ugly Duckling (a shorter length story). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesByChar(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return list(sentence)\n",
    "    def word_join(self, words):\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I knew that I should start with words as the n-gram unit. Breaking it down to character-units seems very specific, and I felt that it would benefit me if I wanted to create some variation with spelling or new word generation (such as the mood generator in the tutorial). However, since I am mainly concerned with the larger sentence portions, I didn't think I would be using SentencesByChar. However, just in case I needed to transition to character n-grams later on, I kept this piece of code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_a = markovify.Text(textA)\n",
    "generator_b = markovify.Text(textB)\n",
    "combo = markovify.combine([generator_a, generator_b], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was really fascinating to me was the markovify.combine feature. Because I intended to combine machine-generated text with user input, I wanted to experiment with this to see what I could do with it. Following the tutorial, I stored both the Dracula text and Ugly Duckling text in their respective 'generator' variables, combined both generators with 50/50 equal weights, and stored them in the 'combo' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I threw on some clothes and got her death-warrant.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite the strange output. This most likely was from the Dracula text since the Ugly Duckling had no clothes or death warrant. I printed another output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were, he said, six in the way that was heart-breaking to hear.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I admit that in all sorts of shapes, as well as I had to hurry breakfast, for the sake of those dear to his old wound might act detrimentally on Jonathan.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seemed that both outputs were mainly from Dracula. I wondered if the size of the text might affect the output in some way, despite both weights being equal. I readjusted the weights again, this time with more emphasis on the Ugly Duckling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = markovify.combine([generator_a, generator_b], [0.2, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, too, shall go with Jack and the occasion, and stood silent, waiting.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = markovify.combine([generator_a, generator_b], [0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Straightway he began to get down and struck him over the jamb of the dogs, and carrying him in, placed him on a butcher's shop in time.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Roumanians were wild, and wanted to get down and the other houses.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But the wind blew so hard that the work if I may.\n"
     ]
    }
   ],
   "source": [
    "print(combo.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted to the extreme (0.1 for Dracula and 0.9 for Ugly Duckling), it seemed that the sentences became more incoherent, which was probably a sign that the Ugly Duckling text was taking over. \n",
    "\n",
    "After playing around a bit more with the values, I was content with using markovify.combine to attempt to create a human-machine co-author piece. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to \"word\" for a word-level model\n",
    "level = \"word\"\n",
    "# controls the length of the n-gram\n",
    "order = 7\n",
    "# controls the number of lines to output\n",
    "output_n = 1\n",
    "# weights between the models; text A first, text B second.\n",
    "# if you want to completely exclude one model, set its corresponding value to 0\n",
    "weights = [0.1, 0.9]\n",
    "# limit sentence output to this number of characters\n",
    "length_limit = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial was absolutely amazing to follow. I changed the n-gram level from char level to word level, fiddled around with the order until I hit a sweet spot, and set the output line to 1 with a 150 character limit. I knew that my 'user corpus' would be pretty small compared to Dracula, so I skewed the weights: 0.1 Dracula, 0.9 User Text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence here:One day a young woman was walking to the store to buy some bread\n"
     ]
    }
   ],
   "source": [
    "textInput = input(\"Sentence here:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He find in patience just how is his strength, and what are his powers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "gen_a = model_cls(textA, state_size=order)\n",
    "gen_b = model_cls(textInput, state_size=order)\n",
    "gen_combo = markovify.combine([gen_a, gen_b], weights)\n",
    "for i in range(output_n):\n",
    "    out = gen_combo.make_short_sentence(length_limit, test_output=False)\n",
    "    out = out.replace(\"\\n\", \" \")\n",
    "    print(out)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a variable to store the user input, and then combined the user input text with the Dracula text using markovify.combine. I received an output, which was a bit surprising since I expected something to go wrong. Of course, given that generator b only had one line of text to work with, I knew that the output was mainly going to be from Dracula. \n",
    "\n",
    "To remedy this, I created an empty \"userinput\" textfile, and continuously added whatever text the user inputted to the file. This way, as the user continues to 'write' the story alongside the predictive-text generator, the User Text File will increase in content as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a young woman was walking to the store to buy some bread\n",
      "\n",
      "He had only one outburst and that was yesterday at an unusual time.\n",
      "\n",
      "Still, the woman thought. She should probably buy some bread for him to feel better\n",
      "\n",
      "I knew the swaying round forms, the bright hard eyes, the white teeth, the ruddy colour, the voluptuous lips.\n",
      "\n",
      "Thinking about his features made her think back to when they first met\n",
      "\n",
      "That going down to the vault a second time was a remarkable piece of daring.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-9359d6360a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtextInput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"userinput.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtextInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtextInput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkovify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"word\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mSentencesByChar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    textInput1 = open(\"userinput.txt\", \"a\")\n",
    "    textInput = input()\n",
    "    textInput1.write(textInput)\n",
    "    model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "    gen_a = model_cls(textA, state_size=order)\n",
    "    gen_b = model_cls(textInput, state_size=order)\n",
    "    gen_combo = markovify.combine([gen_a, gen_b], weights)\n",
    "    for i in range(output_n):\n",
    "        out = gen_combo.make_short_sentence(length_limit, test_output=False)\n",
    "        out = out.replace(\"\\n\", \" \")\n",
    "        print()\n",
    "        print(out)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of my first run. I trapped everything in a while loop (I know...but this is only for testing), and the program began by asking me to type a sentence into the box. \n",
    "\n",
    "I typed out \"One day, a young woman was walking to the store to buy some bread\", to which the generator built off of by saying, \"He had only one outburst and that was yesterday at an unusual time.\" \n",
    "\n",
    "Extending the story, I wrote, \"Still, the woman thought. She should probably buy some bread for him to feel better\", to which the generator writes, \"I knew the swaying round forms, the bright hard eyes, the white teeth, the ruddy colour, the voluptuous lips.\"\n",
    "\n",
    "I thought this was very interesting in that I was technically the one making up meaning for this story, but I was also led on by what the machine was putting out as well. I imagine that if someone were to keep writing alongside the generator, the story would change as the user input textfile gets larger and larger, eventually producing an 'original' work of sorts, co-authored by man and machine. \n",
    "\n",
    "Just to test out if the user text file was actually being written by the user input, I took a peek. Sure enough, the file was getting updated by each new sentence the user was typing in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a young boy was walking through the dark woods\n",
      "\n",
      "There are many ships weighing anchor at the moment in your so great Port of London.\n",
      "\n",
      "Yet, he was not interested in these ships. All he wanted to do was to pick some flowers in the forest clearing\n",
      "\n",
      "The poor fellow was quite broken down; now and again he gave a low groan which he could not suppress--he was thinking of his wife.\n",
      "\n",
      "Even though he looks like a young boy, he was, in reality, a thirty year old man\n",
      "\n",
      "You have copied maps of it, and you know it at least more than we do.\n",
      "\n",
      "His doctor's words echoed through his mind. He remembers looking at the maps of his body, registering his bodily condition\n",
      "\n",
      "We shall in future be able to ease his bonds for a few hours each day.\n",
      "\n",
      "THE END\n"
     ]
    }
   ],
   "source": [
    "ending = False;\n",
    "while ending == False:\n",
    "    textInput1 = open(\"userinput.txt\", \"a\")\n",
    "    textInput = input()\n",
    "    textInput1.write(textInput)\n",
    "    if textInput == \"THE END\":\n",
    "        ending = True;\n",
    "    else:\n",
    "        model_cls = markovify.Text if level == \"word\" else SentencesByChar\n",
    "        gen_a = model_cls(textA, state_size=order)\n",
    "        gen_b = model_cls(textInput, state_size=order)\n",
    "        gen_combo = markovify.combine([gen_a, gen_b], weights)\n",
    "        for i in range(output_n):\n",
    "            out = gen_combo.make_short_sentence(length_limit, test_output=False)\n",
    "            out = out.replace(\"\\n\", \" \")\n",
    "            print()\n",
    "            print(out)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my final output. I made some adjustments by taking out the while loop, and replacing it with conditional logic. As long as the user wants, they can continue writing with the generator. If the user intends to end the story, typing in \"THE END\" in caps will break the loop.\n",
    "\n",
    "I checked the text file, and saw that my corpus was getting larger:\n",
    "\n",
    "*One day, a young woman was walking to the store to buy some breadStill, the woman thought. She should probably buy some bread for him to feel betterThinking about his features made her think back to when they first metOne day, a little boy was walking through the dark woodsThis was the unmistakable feeling of ghosts, the boy thought. He felt that he should probably walk a bit fasterHowever, if Lucy could see me now, she would be horrified at my cowardice, the boy thoughtTHE ENDOne day, a young girl was happily skipping through the woodsThe girl was quite happy with this situation. She had gotten off track a few times when exploring the woods, and this time, she didn't want to lose her way\"Don't worry,\" I told The Professor. That young girl won't lose her way in the woods this timeI remembered that in Lucy's Diary, she had mentioned that the girl suffers from frequent memory loss\"Anyways\" I told the Professor, \"I best be going now\"One day, a young boy was walking through the dark woodsYet, he was not interested in these ships. All he wanted to do was to pick some flowers in the forest clearingEven though he looks like a young boy, he was, in reality, a thirty year old manHis doctor's words echoed through his mind. He remembers looking at the maps of his body, registering his bodily condition*\n",
    "\n",
    "For reference, I have attached the text file to this repository as well.\n",
    "\n",
    "I wrote a short story to test out the process, and the results were quite surprising. I found myself invested in the story I was creating (a 30 year old man who looks like a young boy picking flowers in the woods and having flashbacks at the doctors about his condition), and it felt as if I was under the whim of the machine. Whatever the generator spat out, I bent over backwards to accomodate and spin the story in a way that made sense. In this fashion, it seems that the generator had power over me, despite the fact that we were supposed to be co-authors.\n",
    "\n",
    "I really enjoyed working with markov chains and predictive text generation. I feel that I may explore this further for my final project as well. It would also be interesting to see if I can keep writing with the generator and build a larger corpus over time as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
